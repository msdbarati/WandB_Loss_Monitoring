{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ANN and Classification in Power Systems with WandB Monitoring\n",
        "\n",
        "This notebook implements an Artificial Neural Network for power system event detection with comprehensive Weights & Biases (WandB) monitoring for tracking training progress, loss curves, and model performance."
      ],
      "metadata": {
        "id": "fmIu6Rkmi2Aj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installation and Setup"
      ],
      "metadata": {
        "id": "setup-section"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Weights & Biases\n",
        "!pip install wandb -qU"
      ],
      "metadata": {
        "id": "install-wandb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "import wandb"
      ],
      "metadata": {
        "id": "9ix-tRw1dq8I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Login to WandB with your API key\n",
        "# Replace with your actual API key or use wandb.login() for interactive login\n",
        "wandb.login(key=\"use your won API from WandB site. Just copy paste your API code here\")"
      ],
      "metadata": {
        "id": "wandb-login"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Generation\n",
        "\n",
        "Generating synthetic data for 10 PMUs with 14 features each:\n",
        "- Magnitude of current for phases a, b, c\n",
        "- Magnitude of voltage for phases a, b, c\n",
        "- Phase angles for voltage and current\n",
        "- Frequency and Rate of Change of Frequency (ROCOF)\n",
        "\n",
        "Event labels:\n",
        "- 0: Normal\n",
        "- 1: Phase Angle Instability\n",
        "- 2: Low Frequency Instability\n",
        "- 3: Voltage Instability\n",
        "- 4: Large Signal Instability"
      ],
      "metadata": {
        "id": "data-section"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set seed for reproducibility\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Define the number of PMUs and features per PMU\n",
        "num_pm = 10  # Number of PMUs\n",
        "num_features = 14  # Features as specified\n",
        "\n",
        "# Define bounds for reasonable power system data (based on common ranges)\n",
        "bounds = {\n",
        "    \"mag_I\": (0, 200), \"mag_V\": (110, 140),\n",
        "    \"angle_V\": (-180, 180), \"angle_I\": (-180, 180),\n",
        "    \"frequency\": (59.5, 60.5), \"ROCOF\": (-2, 2),\n",
        "}\n",
        "\n",
        "# Generate synthetic data\n",
        "def generate_synthetic_data(num_samples):\n",
        "    data, labels = [], []\n",
        "    for _ in range(num_samples):\n",
        "        sample = []\n",
        "        for _ in range(num_pm):\n",
        "            sample.extend(np.random.uniform(bounds[\"mag_I\"][0], bounds[\"mag_I\"][1], 3))\n",
        "            sample.extend(np.random.uniform(bounds[\"mag_V\"][0], bounds[\"mag_V\"][1], 3))\n",
        "            sample.extend(np.random.uniform(bounds[\"angle_V\"][0], bounds[\"angle_V\"][1], 3))\n",
        "            sample.extend(np.random.uniform(bounds[\"angle_I\"][0], bounds[\"angle_I\"][1], 3))\n",
        "            sample.append(np.random.uniform(bounds[\"frequency\"][0], bounds[\"frequency\"][1]))\n",
        "            sample.append(np.random.uniform(bounds[\"ROCOF\"][0], bounds[\"ROCOF\"][1]))\n",
        "\n",
        "        label = np.random.choice([0, 1, 2, 3, 4])\n",
        "        labels.append(label)\n",
        "        data.append(sample)\n",
        "\n",
        "    return np.array(data), np.array(labels)\n",
        "\n",
        "# Generate 100 samples\n",
        "X, y = generate_synthetic_data(100)\n",
        "print(f\"Generated data shape: {X.shape}\")\n",
        "print(f\"Labels shape: {y.shape}\")"
      ],
      "metadata": {
        "id": "UQBNl5gneDkE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing"
      ],
      "metadata": {
        "id": "preprocessing-section"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Training set size: {X_train.shape}\")\n",
        "print(f\"Test set size: {X_test.shape}\")"
      ],
      "metadata": {
        "id": "MfvLibp1eIaQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Definition\n",
        "\n",
        "Defining a multi-layer ANN with:\n",
        "- Input layer: 140 features (10 PMUs × 14 features)\n",
        "- Hidden layers: 128 → 64 → 32 neurons\n",
        "- Output layer: 5 classes\n",
        "- Activation: ReLU for hidden layers"
      ],
      "metadata": {
        "id": "model-section"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the ANN model\n",
        "class ANN_Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ANN_Model, self).__init__()\n",
        "        self.fc1 = nn.Linear(num_pm * num_features, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 32)\n",
        "        self.fc4 = nn.Linear(32, 5)  # 5 output classes\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = torch.relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        return x\n",
        "\n",
        "# Initialize model, loss function, and optimizer\n",
        "model = ANN_Model()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Convert data to tensors\n",
        "X_train_tensor = torch.FloatTensor(X_train)\n",
        "y_train_tensor = torch.LongTensor(y_train)\n",
        "X_test_tensor = torch.FloatTensor(X_test)\n",
        "y_test_tensor = torch.LongTensor(y_test)\n",
        "\n",
        "print(\"Model architecture:\")\n",
        "print(model)"
      ],
      "metadata": {
        "id": "0x1MR3roeO1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training with WandB Monitoring\n",
        "\n",
        "Training the model with comprehensive WandB tracking:\n",
        "- Training loss per epoch\n",
        "- Validation/test accuracy\n",
        "- Hyperparameters\n",
        "- System metrics"
      ],
      "metadata": {
        "id": "training-section"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize WandB run\n",
        "wandb.init(\n",
        "    project=\"power-system-classification\",\n",
        "    name=\"ann-pmu-classification\",\n",
        "    config={\n",
        "        \"learning_rate\": 0.001,\n",
        "        \"architecture\": \"ANN\",\n",
        "        \"dataset\": \"PMU-Power-System\",\n",
        "        \"epochs\": 50,\n",
        "        \"num_pmus\": num_pm,\n",
        "        \"num_features\": num_features,\n",
        "        \"hidden_layers\": [128, 64, 32],\n",
        "        \"optimizer\": \"Adam\",\n",
        "        \"batch_size\": \"full_batch\",\n",
        "        \"num_classes\": 5,\n",
        "        \"train_samples\": len(X_train),\n",
        "        \"test_samples\": len(X_test)\n",
        "    }\n",
        ")\n",
        "\n",
        "# Log model architecture\n",
        "wandb.watch(model, log=\"all\", log_freq=10)\n",
        "\n",
        "# Train the model\n",
        "num_epochs = 50\n",
        "train_losses = []\n",
        "\n",
        "print(\"Starting training...\")\n",
        "for epoch in range(num_epochs):\n",
        "    # Training step\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(X_train_tensor)\n",
        "    loss = criterion(outputs, y_train_tensor)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    train_losses.append(loss.item())\n",
        "\n",
        "    # Validation step\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        test_outputs = model(X_test_tensor)\n",
        "        test_loss = criterion(test_outputs, y_test_tensor)\n",
        "        _, predicted = torch.max(test_outputs, 1)\n",
        "        test_accuracy = accuracy_score(y_test, predicted.numpy())\n",
        "\n",
        "    # Log metrics to WandB\n",
        "    wandb.log({\n",
        "        \"epoch\": epoch + 1,\n",
        "        \"train_loss\": loss.item(),\n",
        "        \"test_loss\": test_loss.item(),\n",
        "        \"test_accuracy\": test_accuracy,\n",
        "        \"learning_rate\": optimizer.param_groups[0]['lr']\n",
        "    })\n",
        "\n",
        "    # Print progress every 10 epochs\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}] - Train Loss: {loss.item():.4f}, Test Loss: {test_loss.item():.4f}, Test Accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "print(\"\\nTraining completed!\")"
      ],
      "metadata": {
        "id": "training-loop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Evaluation and Visualization"
      ],
      "metadata": {
        "id": "evaluation-section"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Final evaluation\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    outputs = model(X_test_tensor)\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    final_accuracy = accuracy_score(y_test, predicted.numpy())\n",
        "\n",
        "print(f\"\\nFinal Test Accuracy: {final_accuracy:.4f}\")\n",
        "\n",
        "# Class labels\n",
        "class_names = ['Normal', 'Phase Angle', 'Low Freq Instability',\n",
        "               'Voltage Instability', 'Large Signal Instability']\n",
        "\n",
        "# Classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, predicted.numpy(), target_names=class_names))\n",
        "\n",
        "# Log final metrics to WandB\n",
        "wandb.summary['final_test_accuracy'] = final_accuracy"
      ],
      "metadata": {
        "id": "final-evaluation"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training loss\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(train_losses, label='Training Loss', linewidth=2)\n",
        "plt.xlabel('Epoch', fontsize=12)\n",
        "plt.ylabel('Loss', fontsize=12)\n",
        "plt.title('Training Loss over Epochs', fontsize=14)\n",
        "plt.legend(fontsize=10)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "\n",
        "# Log plot to WandB\n",
        "wandb.log({\"training_loss_plot\": wandb.Image(plt)})\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "plot-loss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, predicted.numpy())\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=class_names, yticklabels=class_names,\n",
        "            cbar_kws={'label': 'Count'})\n",
        "plt.xlabel('Predicted Label', fontsize=12)\n",
        "plt.ylabel('True Label', fontsize=12)\n",
        "plt.title('Confusion Matrix', fontsize=14)\n",
        "plt.tight_layout()\n",
        "\n",
        "# Log confusion matrix to WandB\n",
        "wandb.log({\"confusion_matrix\": wandb.Image(plt)})\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "confusion-matrix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create WandB confusion matrix (interactive)\n",
        "wandb.log({\n",
        "    \"conf_mat\": wandb.plot.confusion_matrix(\n",
        "        probs=None,\n",
        "        y_true=y_test,\n",
        "        preds=predicted.numpy(),\n",
        "        class_names=class_names\n",
        "    )\n",
        "})"
      ],
      "metadata": {
        "id": "wandb-confusion-matrix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save Model to WandB"
      ],
      "metadata": {
        "id": "save-section"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model checkpoint\n",
        "model_path = \"power_system_ann_model.pt\"\n",
        "torch.save({\n",
        "    'epoch': num_epochs,\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict(),\n",
        "    'train_loss': train_losses[-1],\n",
        "    'test_accuracy': final_accuracy,\n",
        "}, model_path)\n",
        "\n",
        "# Log model to WandB\n",
        "wandb.save(model_path)\n",
        "print(f\"\\nModel saved to {model_path} and uploaded to WandB\")"
      ],
      "metadata": {
        "id": "save-model"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Finish WandB run\n",
        "wandb.finish()\n",
        "print(\"\\nWandB run finished. Check your WandB dashboard for detailed metrics and visualizations!\")"
      ],
      "metadata": {
        "id": "finish-wandb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary\n",
        "\n",
        "This notebook demonstrates:\n",
        "1. **Data Generation**: Synthetic PMU data with realistic power system values\n",
        "2. **Model Architecture**: Multi-layer ANN for 5-class classification\n",
        "3. **WandB Integration**:\n",
        "   - Real-time loss monitoring\n",
        "   - Accuracy tracking\n",
        "   - Hyperparameter logging\n",
        "   - Model checkpointing\n",
        "   - Confusion matrix visualization\n",
        "4. **Performance Metrics**: Classification report and confusion matrix\n",
        "\n",
        "### Next Steps:\n",
        "- Visit your WandB dashboard to explore interactive charts\n",
        "- Compare multiple runs with different hyperparameters\n",
        "- Share results with your team\n",
        "- Use WandB Sweeps for hyperparameter optimization"
      ],
      "metadata": {
        "id": "summary-section"
      }
    }
  ]
}